{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "418a2a8a-1d90-48b3-ae7a-271e936d5348",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ../.././start_up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0cf6791-ea95-4b94-baf6-c5f8e5abdb6f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "logger = create_logger(notebook_name=\"landing_to_bronze\", log_level=\"DEBUG\")\n",
    "logger.info(\"ðŸš€ Initializing landing_to_bronze notebook\")\n",
    "\n",
    "# Extract frequently used config values into variables\n",
    "catalog = pipeline_config[\"catalog\"]\n",
    "bronze_schema = pipeline_config[\"schemas\"][\"bronze\"]\n",
    "bronze_path = pipeline_config[\"paths\"][\"bronze_path\"]\n",
    "landing_schema= pipeline_config[\"schemas\"][\"landing\"]\n",
    "landing_path = pipeline_config[\"paths\"][\"landing_path\"]\n",
    "bronze_volume_path = pipeline_config[\"paths\"][\"bronze_volume_path\"]\n",
    "logs_schema = pipeline_config[\"schemas\"][\"logs\"]\n",
    "logger.info(\"Extracted frequently used config values into variables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "373d4804-279b-4749-ab51-932b6f12d784",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "# === Create Volume ===\n",
    "spark.sql(f\"\"\"\n",
    "    CREATE VOLUME IF NOT EXISTS {catalog}.{bronze_schema}.{bronze_volume_name}\n",
    "\"\"\")\n",
    "\n",
    "# === Loop through each file and ingest ===\n",
    "for file in tables_to_process:\n",
    "    input_path = f\"{landing_path}/{file}.csv\"\n",
    "    \n",
    "    df = (\n",
    "        spark.read.format(\"csv\")\n",
    "        .option(\"header\", \"true\")\n",
    "        .load(input_path)\n",
    "        .withColumn(\"ingestion_date\", current_timestamp())\n",
    "    )\n",
    "\n",
    "    # display(df)\n",
    "\n",
    "    # Write to Delta inside the volume (as a folder for each table)\n",
    "    df.coalesce(1).write.format(\"csv\") \\\n",
    "        .option(\"header\",\"true\") \\\n",
    "        .mode(\"overwrite\") \\\n",
    "        .save(f\"{bronze_volume_path}/{file}\")\n",
    "\n",
    "    logger.info(f\"âœ… Ingested {file}.csv into volume {bronze_volume_name} under folder {file}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 4976989594781989,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Landing_to_bronze",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
